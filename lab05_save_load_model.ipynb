{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIsTWNrUkHlz"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook, we are using the Keras API in Tensorflow 2.X to build an image classifier to recognize Handwritten digits using the Mnist data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9jkOW0BkFoO"
      },
      "source": [
        "# Loading Tensorflow and checking the version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whClKcLBkVLV",
        "outputId": "d4bd4bc6-0999-479a-dffa-559a93e0d119"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72OsafxTkePO"
      },
      "source": [
        "- If not installed, uncomment the following cell.\n",
        "- **PS:** using pip not conda as everything on colab is prepared for you (cuda).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JL5w4z1qkfCn"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow==2.5.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAUyfyCGkosR"
      },
      "source": [
        "# Data Loading and exploring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuoR7D5Oksiu",
        "outputId": "de7a2087-1558-4570-eeab-dd40ace1113e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(training_images, training_labels), (testing_images, testing_labels) = mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Lgse1mloXb",
        "outputId": "fa06d635-bae8-4449-b92c-f8a40f608465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of training images is 60000\n",
            "The number of testing images is 10000\n",
            "The shape of an image is 28X28\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of training images is {}\".format(training_images.shape[0]))\n",
        "print(\"The number of testing images is {}\".format(testing_images.shape[0]))\n",
        "print(\n",
        "    \"The shape of an image is {}X{}\".format(\n",
        "        training_images.shape[1], training_images.shape[2]\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wJYUk6GrlGmp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "YboJdayulamy",
        "outputId": "7fe49073-8fbb-4ca9-c72b-0a98f1281a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "img_number = random.randint(0, training_images.shape[0])\n",
        "plt.imshow(training_images[img_number])\n",
        "print(training_labels[img_number])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsFk7rY5mWpo"
      },
      "source": [
        "All of the pixels values are between 0 and 255. If we are training a neural network, for various reasons it's easier that all values are between 0 and 1.\n",
        "\n",
        "This can be done using `normalizing`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kb7d3LjcnB58"
      },
      "outputs": [],
      "source": [
        "training_images = training_images / 255.0\n",
        "testing_images = testing_images / 255.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXQ0kOROnflN"
      },
      "source": [
        "# Defining the model using **Sequential** API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "p9rkDIjdngXM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "56pQNcXJnoQu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-25 21:29:46.536282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-01-25 21:29:46.546240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-01-25 21:29:46.546721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-01-25 21:29:46.547540: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-01-25 21:29:46.548056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-01-25 21:29:46.548363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-01-25 21:29:46.548611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-01-25 21:29:47.055001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-01-25 21:29:47.055315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-01-25 21:29:47.055560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-01-25 21:29:47.055782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1097 MB memory:  -> device: 0, name: Quadro M1000M, pci bus id: 0000:01:00.0, compute capability: 5.0\n"
          ]
        }
      ],
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(128, activation=tf.nn.relu),\n",
        "        Dense(10, activation=tf.nn.softmax),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzAMbAzMtSWw",
        "outputId": "3d04d296-d267-427a-859c-eea5607b8ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmI9EO-8n9U4"
      },
      "source": [
        "Define the **optimizer** and the **loss**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cVS9wyG9n_cE"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m-li45MojR6"
      },
      "source": [
        "Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94PtEBCwog6s",
        "outputId": "0203a04b-de88-42a3-c07c-d38176a6ad76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2556 - accuracy: 0.9269\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1151 - accuracy: 0.9654\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0784 - accuracy: 0.9765\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0591 - accuracy: 0.9821\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0464 - accuracy: 0.9857\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89621bad30>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(training_images, training_labels, epochs=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qQXQdWnolTu"
      },
      "source": [
        "Evaluate the model on the test images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC_Ium0nooci",
        "outputId": "e8a0d771-a61d-4429-f4ac-90f34eada932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.0784 - accuracy: 0.9752\n",
            "Accuracy on the testing images is 97.51999974250793\n"
          ]
        }
      ],
      "source": [
        "evaluation = model.evaluate(testing_images, testing_labels)\n",
        "print(\"Accuracy on the testing images is {}\".format(evaluation[1] * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5oOcjUM3uXW"
      },
      "source": [
        "# Save and Load a Model\n",
        "\n",
        "A model's architecture, weights, and training configuration can be saved in a single file/folder which allows accessing a model without the need for the python source code\n",
        "\n",
        "- SavedModel format\n",
        "- HDF5 format\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5Q-TkIO6IsJ"
      },
      "source": [
        "## SavedModel format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJUd5zwS31TC",
        "outputId": "2bdd853d-21c6-4165-fb7d-95bc4f07c7db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-25 21:32:16.147314: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('saved_model/my_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de_yx0jM4B5g",
        "outputId": "1468becc-bd05-4ae2-aa8d-fa431c6f81bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "new_model = load_model(\"saved_model/my_model\")\n",
        "\n",
        "# Check its architecture\n",
        "new_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU1g3-Ec50Az",
        "outputId": "c34d83f4-f7e0-492e-8f90-645bb594c494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0784 - accuracy: 0.9752\n",
            "Accuracy on the testing images is 97.51999974250793\n"
          ]
        }
      ],
      "source": [
        "evaluation = new_model.evaluate(testing_images, testing_labels)\n",
        "print(\"Accuracy on the testing images is {}\".format(evaluation[1] * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZUGpPgz74OT"
      },
      "source": [
        "## HDF5 format\n",
        "\n",
        "A basic save format using the **HDF5** standard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "R_9riC2Z8DGj"
      },
      "outputs": [],
      "source": [
        "model.save(\"my_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfsK0OxG8MKm",
        "outputId": "97e04c2e-6564-4dae-a08c-437a409d9c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "new_model_h5 = load_model(\"my_model.h5\")\n",
        "\n",
        "# Check its architecture\n",
        "new_model_h5.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qiv8_XoJ8VXA",
        "outputId": "113df322-d3af-4d48-a0e0-511d98618cde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0784 - accuracy: 0.9752\n",
            "Accuracy on the testing images is 97.51999974250793\n"
          ]
        }
      ],
      "source": [
        "evaluation = new_model_h5.evaluate(testing_images, testing_labels)\n",
        "print(\"Accuracy on the testing images is {}\".format(evaluation[1] * 100))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "lab05_save_load_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
